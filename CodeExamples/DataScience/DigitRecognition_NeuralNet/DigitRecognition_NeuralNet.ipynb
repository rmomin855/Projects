{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 ALIGN=RIGHT>MAT 345: Assignment 5</h5>\n",
    "<h1 ALIGN=CENTER>Neural Net Digit Recognition</h1>\n",
    "<h3>By: Bradley Esparza, Rahil Momin</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gzip\n",
    "from mnist import MNIST\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error",
     "output_type": "error"
    }
   ],
   "source": [
    "# Step 1: Sigmoid\n",
    "\n",
    "# Sigmoid function for single value\n",
    "def sigmoid_base(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# Sigmoid function for a matrix\n",
    "def sigmoid(X):\n",
    "    result = np.matrix(X)\n",
    "    row = np.size(X[0])\n",
    "    for i in range(row):\n",
    "        for j in range(int(np.size(X) / row)):\n",
    "            result[j,i] = sigmoid_base(X[j,i])\n",
    "            pass\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "# Sigmoid prime function for a matrix\n",
    "def sigmoidPrime(zk):\n",
    "    ak = sigmoid(zk)\n",
    "    return np.multiply(ak, 1 - ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error",
     "output_type": "error"
    }
   ],
   "source": [
    "# Create the Y label, ex, label=2 = [0, 1, 0, ..., 0], (1x10)\n",
    "# index 0 represents 1, index 9 represents 0\n",
    "def CreateLabelMatrix(label):\n",
    "    index = label - 1\n",
    "    if(index == -1):\n",
    "        index = 9\n",
    "        pass\n",
    "    result = np.zeros((10,))\n",
    "    result[index] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error",
     "output_type": "error"
    }
   ],
   "source": [
    "# Load in the data using MNIST\n",
    "mndata = MNIST('Data')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    # input D: DataSet(All images)\n",
    "    # input L: LabelSet(All labels)\n",
    "    # input S2: number of nodes in hidden layer\n",
    "    def __init__(self, D, L, S2):\n",
    "        self.D  = D\n",
    "        self.L  = L\n",
    "        self.S2 = S2\n",
    "        \n",
    "        # Random epsilon\n",
    "        epsilon = sys.float_info.epsilon\n",
    "    \n",
    "        # Step 2. Initialize W1 and W2 with proper dimensions\n",
    "        W1 = np.random.random((S2, len(D[0]) + 1))\n",
    "        W1 = W1 * 2 * epsilon\n",
    "        self.W1 = W1 - epsilon\n",
    "\n",
    "        W2 = np.random.random((10, S2 + 1))\n",
    "        W2 = W2 * 2 * epsilon\n",
    "        self.W2 = W2 - epsilon\n",
    "        \n",
    "        self.gradW1 = np.zeros((S2, len(D[0]) + 1))\n",
    "        self.gradW2 = np.zeros((10, S2 + 1))\n",
    "\n",
    "        pass\n",
    "    \n",
    "    # Step 5:\n",
    "    def GradiantDescent(self):\n",
    "        # b.) Choose step\n",
    "        step = sys.float_info.epsilon\n",
    "\n",
    "        # c.) Update rule: for k=1,2\n",
    "        #   Wk_t+1 = Wk_t - step * gradWk_t\n",
    "\n",
    "        maxIteration = 100\n",
    "        tollerance = 0.001\n",
    "        tolleranceArray1 = np.full(self.W1.shape, tollerance)\n",
    "        tolleranceArray2 = np.full(self.W2.shape, tollerance)\n",
    "\n",
    "        for i in range(maxIteration):\n",
    "            print(\"itter:\", i, end=\"\\r\")\n",
    "            # a.) Weights initialized\n",
    "            self.feedforward_backprop() # FOREVER\n",
    "            \n",
    "            # use logistic regression\n",
    "            W1_n = self.W1 - np.multiply(step, self.gradW1)\n",
    "\n",
    "            if (abs(self.W1 - W1_n) < tolleranceArray1).all():\n",
    "                self.W1 = W1_n\n",
    "                break\n",
    "\n",
    "            # check for iteration\n",
    "            if i == (maxIteration - 1):\n",
    "                self.W1 = W1_n\n",
    "                break\n",
    "\n",
    "            self.W1 = W1_n\n",
    "            pass\n",
    "        print(\"DONE with W1!\")\n",
    "        \n",
    "        for i in range(maxIteration):\n",
    "            print(\"itter:\", i, end=\"\\r\")\n",
    "            # a.) Weights initialized\n",
    "            self.feedforward_backprop() # FOREVER\n",
    "            \n",
    "            # use logistic regression\n",
    "            W2_n = self.W2 - np.multiply(step, self.gradW2)\n",
    "\n",
    "            if (abs(self.W2 - W2_n) < tolleranceArray2).all():\n",
    "                self.W2 = W2_n\n",
    "                break\n",
    "\n",
    "            # check for iteration\n",
    "            if i == (maxIteration - 1):\n",
    "                self.W2 = W2_n\n",
    "                break\n",
    "                \n",
    "            self.W2 = W2_n\n",
    "            pass\n",
    "        print(\"DONE with W2!\")\n",
    "        \n",
    "    # Step 3: For each Datapoint in D:\n",
    "    def feedforward_backprop(self):\n",
    "\n",
    "        # For each datapoint, feed forward and back propagate\n",
    "        for i in range(len(self.D)):\n",
    "            # initialize x and y for use\n",
    "            self.x = self.D[i]\n",
    "            self.y = CreateLabelMatrix(self.L[i]).reshape(-1,1)\n",
    "            \n",
    "            self.feedforward()\n",
    "            self.backprop()\n",
    "            pass\n",
    "        \n",
    "        # Average the gradiants \n",
    "        self.gradW1 = self.gradW1 / len(self.D)\n",
    "        self.gradW2 = self.gradW2 / len(self.D)\n",
    "        pass\n",
    "    \n",
    "    def feedforward(self):\n",
    "        # a.) Let a1 = [1, X] (with bais term)\n",
    "        self.a1 = np.column_stack((1,np.matrix(self.x))).reshape(-1,1)\n",
    "\n",
    "        # b.) Let z2 = W1*a1 (dim S2x1)\n",
    "        self.z2 = (self.W1*self.a1)\n",
    "        \n",
    "        # c.) Let a2 = sigmoid(z2), and add bias term\n",
    "        self.a2 = np.row_stack((1,sigmoid(self.z2)))\n",
    "\n",
    "        # d.) Let z3 = W2*a2 (dim 10x1)\n",
    "        self.z3 = self.W2*self.a2\n",
    "        \n",
    "        # e.) Let a3 = sigmoid(z3)\n",
    "        self.a3 = sigmoid(self.z3)\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def backprop(self):\n",
    "        # a.) Let d3 = a3 - y (dim 10x1)\n",
    "        d3 = self.a3 - self.y\n",
    "\n",
    "        # b.1) Let W~2 be W2 with bias term removed, (dim 10xS2)\n",
    "        W_t2 = np.delete(self.W2, 0, axis=1)\n",
    "\n",
    "        # b.2) Let d2 = [W~2].T * d3 (x) sigmoid_prime(z2), (dim S2x1)\n",
    "        d2 = np.multiply(W_t2.T * d3, sigmoidPrime(self.z2))\n",
    "\n",
    "        # c.) Compute set of partial derivatives wrt. the weights, k=1,2\n",
    "        #     gW1(x,y) = d2[a1].T --> size S2x785\n",
    "        #     gW2(x,y) = d3[a2].T --> size 10x(S2+1)\n",
    "        gW1 = d2 * self.a1.T\n",
    "        gW2 = d3 * self.a2.T\n",
    "        \n",
    "        self.gradW1 = self.gradW1 + np.sum(gW1)\n",
    "        self.gradW2 = self.gradW2 +  np.sum(gW2)\n",
    "\n",
    "        pass\n",
    "            \n",
    "    \n",
    "    def predictSingle(self, x):\n",
    "        a1 = np.matrix(x)\n",
    "        a1 = np.column_stack((1,a1)).reshape(-1,1)\n",
    "        \n",
    "        z2 = (self.W1*a1)\n",
    "        a2 = np.row_stack((1,sigmoid(z2)))\n",
    "\n",
    "        z3 = self.W2*a2\n",
    "        a3 = sigmoid(z3)\n",
    "        self.output = a3\n",
    "        \n",
    "        result = np.argmax(a3) + 1\n",
    "        if(result == 10):\n",
    "            result = 0\n",
    "            pass\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predictData(self, D2, L2):\n",
    "        numberArray = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        numberArrayPred = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        correct = 0\n",
    "        for i in range(len(D2)):\n",
    "            predicted = self.predictSingle(D2[i])\n",
    "            numberArray[L2[i]] += 1\n",
    "            if predicted == L2[i]:\n",
    "                correct += 1\n",
    "                numberArrayPred[predicted] += 1\n",
    "                pass\n",
    "            pass\n",
    "        print(\"Correct:\", correct, \" Total:\", len(L2))\n",
    "        print(\"Accuracy:\", correct / len(L2) * 100, \"%\")\n",
    "        \n",
    "        print(\"Number, PredictedRight, Total\")\n",
    "        for i in range(10):\n",
    "            print(i, \"  ,\", numberArrayPred[i], numberArray[i])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Done!\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(train_images, train_labels, 100)\n",
    "print(\"NN Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE with W1!\n",
      "DONE with W2!\n"
     ]
    }
   ],
   "source": [
    "nn.GradiantDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 892  Total: 10000\n",
      "Accuracy: 8.92 %\n",
      "Number, PredictedRight, Total\n",
      "0   , 0 980\n",
      "1   , 0 1135\n",
      "2   , 0 1032\n",
      "3   , 0 1010\n",
      "4   , 0 982\n",
      "5   , 892 892\n",
      "6   , 0 958\n",
      "7   , 0 1028\n",
      "8   , 0 974\n",
      "9   , 0 1009\n"
     ]
    }
   ],
   "source": [
    "nn.predictData(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorset = np.matrix([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "output = np.matrix([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itter: 0\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,785) and (3,1) not aligned: 785 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2b7aa5c6075b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxorset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradiantDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxorset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a6f8b495df01>\u001b[0m in \u001b[0;36mGradiantDescent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"itter:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# a.) Weights initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# FOREVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# use logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a6f8b495df01>\u001b[0m in \u001b[0;36mfeedforward_backprop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateLabelMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a6f8b495df01>\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# b.) Let z2 = W1*a1 (dim S2x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# c.) Let a2 = sigmoid(z2), and add bias term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,785) and (3,1) not aligned: 785 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(xorset, output, 2)\n",
    "nn.GradiantDescent()\n",
    "nn.predictData(xorset, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}